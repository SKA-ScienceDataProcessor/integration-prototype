# Accept logs from Docker Fluentd log driver
<source>
  @type forward
  port 24224
  bind 0.0.0.0
</source>

<filter *.**>
  @type parser
  key_name log
  format /(?<Timestamp>\S+ \S+)\s+[|]\s+(?<programname>\S+)\s+[|]\s+(?<log_level>\S+)\s*[|]?\s*(?<thread>.*)\s+[|]\s+(?<log>.*)/
  time_key Timestamp
  time_format %Y-%m-%d %H:%M:%S.%N
</filter>

# Add a timestamp dimension with ms precision to all logs to record
# the event time. The event time is the time extracted from the log
# message in all cases where the time_key is set, and the time the
# record entered fluentd if no time_key is set logs.
# NOTE: ISO8601 is used to be compatible with the Monasca pipeline.
<filter *.**>
  @type record_transformer
  enable_ruby
  <record>
    timestamp ${time.strftime('%Y-%m-%dT%H:%M:%S.%3NZ')}
  </record>
</filter>

# Docker saves all logs under the 'log' field. The fluentd-monasca
# plugin assumes that they are saved under the 'message' field. Here
# we map the 'log' field to the 'message' field for all logs. If
# we do this directly in the first format filter, rather than here,
# the record_transformer filter fails with an error about the
# missing log field (Fluent v0.14).
<filter *.**>
  @type record_transformer
  enable_ruby true
  <record>
    message ${record["log"]}
  </record>
  remove_keys log
</filter>

<match *.**>
    @type copy
    <store>
       @type monasca
       keystone_url http://10.60.253.1:5000/v3
       monasca_log_api http://10.60.253.1:5607
       monasca_log_api_version v3.0
       username p3-monasca-agent
       password abc123
       domain_id default
       project_name p3
    </store>
</match>
