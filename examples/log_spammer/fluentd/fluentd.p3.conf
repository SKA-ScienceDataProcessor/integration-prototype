
# Accept logs from Docker Fluentd log driver
<source>
    @type forward
    port 24224
    bind 0.0.0.0
</source>

# Parse the log message.
<filter *.**>
    @type parser
    key_name log
    format /(?<time_stamp>\d{4}-\d{2}-\d{2}[T ]\d{2}:\d{2}:\d{2}[.,]\d{3,6}Z)\s+[-|]\s+(?<module>\S+)\s+[-|]\s+(?<level>\S+)\s+[-|]?\s+(?<thread>.*)\s+[-|]\s+(?<log>.*)/
    time_key time_stamp
    time_format %Y-%m-%dT%H:%M:%S.%NZ
</filter>

# Add a timestamp dimension with ms precision to all logs to record
# the event time. The event time is the time extracted from the log
# message in all cases where the time_key is set, and the time the
# record entered fluentd if no time_key is set logs.
# NOTE: ISO8601 is used to be compatible with the Monasca pipeline.
<filter *.**>
    @type record_transformer
    enable_ruby true
    <record>
        timestamp ${time.strftime('%Y-%m-%dT%H:%M:%S.%6NZ')}
    </record>
</filter>

# Docker saves all logs under the 'log' field. The fluentd-monasca
# plugin assumes that they are saved under the 'message' field. Here
# we map the 'log' field to the 'message' field for all logs. If
# we do this directly in the first format filter, rather than here,
# the record_transformer filter fails with an error about the
# missing log field (Fluent v0.14).
<filter *.**>
    @type record_transformer
    enable_ruby true
    <record>
        message ${record["log"]}
        docker_tag ${tag}
    </record>
    remove_keys log
</filter>

<match *.**>
    @type copy
    <store>
        @type monasca
        keystone_url http://10.60.253.1:5000/v3
        monasca_log_api http://10.60.253.1:5607
        monasca_log_api_version v3.0
        username p3-monasca-agent
        password ****
        domain_id default
        project_name p3
    </store>
</match>
